{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "We would like you to demonstrate your skills in simple data manipulation and analysis. We are looking to understand how you approach the problem and knowledge of programming / data analysis skills, attention to detail and ability to learn new things on the fly.\n",
    "\n",
    "### Data\n",
    "We have provided you with a dataset of app reviews for the popular reddit app. The CSV file has multiple flaws and falls short of what we would like to work with, as is often the case and therefore we want you to fix it.\n",
    "\n",
    "### Expected Output\n",
    "We expect you to parse the file and make sure that things are consistent and as orderly as possible. For example the app_bought and money_spent variables should be available in buckets (feel free to choose the buckets yourself). We will leave it to you to define what is desirable.\n",
    "\n",
    "You should produce these outputs in a ZIP archive or as Pull Request to this repo:\n",
    "\n",
    "A new CSV file with clean data (see above) We would want you to populate the reviews table in exercise_database.db (a SQLlite database). It holds the following columns: review title iso score date apps_bought money_spent apps_bought_bucket money_spent_bucket TEXT TEXG TEXT INTEGER TEXT INTEGER NUMERIC TEXT TEXT Add the updated exercise_database.db and the code used to populate the database to the archive.\n",
    "\n",
    "Once you have the table ready, please write SQL queries to fetch the following metrics from the reviews table. Average score by iso Maximum score by app_bought_bucket Average score over time (day) Add the code used to generate the queries and a CSV with results into the archive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime, time\n",
    "import sqlite3\n",
    "from pandas import DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a short mapper that bins data\n",
    "def map_bin(x, bins):\n",
    "    kwargs = {}\n",
    "    if x == max(bins):\n",
    "        kwargs['right'] = True\n",
    "    bin = bins[np.digitize([x], bins, **kwargs)[0]]\n",
    "    bin_lower = bins[np.digitize([x], bins, **kwargs)[0]-1]\n",
    "    return '[{0}-{1}]'.format(bin_lower, bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_df(df):\n",
    "    #declare bins\n",
    "    app_bought_bins = np.array([0, 20, 40, 60, 80, 100])\n",
    "    money_spent_bins = np.array([0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500])\n",
    "\n",
    "    #make the bins for apps bought and money spent\n",
    "    df['apps_bought_bucket'] = df['app_bought'].apply(map_bin, bins=app_bought_bins)\n",
    "    df['money_spent_bucket'] = df['money_spent'].apply(map_bin, bins=money_spent_bins)\n",
    "\n",
    "    #aligning names with database\n",
    "    df=df.rename(columns = {\"app_bought\": \"apps_bought\"})\n",
    "    df = df.drop('product_name', 1)\n",
    "    \n",
    "    cleaned_dates = clean_dates(df)\n",
    "    df['dates'] = cleaned_dates \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dates(df):\n",
    "    cleaned_dates = []\n",
    "    year_without_padding = '%y-%m-%d %H:%M:%S'\n",
    "    day_month_year = '%d/%m/%y'\n",
    "    year_with_padding = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "    for date in df['date']:\n",
    "        if (convert_date(date, year_without_padding)):\n",
    "            cleaned_dates.append(convert_date(date, year_without_padding))\n",
    "        elif (convert_date(date, day_month_year)):\n",
    "            cleaned_dates.append(convert_date(date, day_month_year))\n",
    "        elif (convert_date(date, year_with_padding)):\n",
    "            cleaned_dates.append(convert_date(date, year_with_padding))\n",
    "        else:\n",
    "            print(\"fail\")\n",
    "            \n",
    "    return cleaned_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date, date_format):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(date, date_format)\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_db(df):\n",
    "    conn = sqlite3.connect(\"exercise_database.db\")\n",
    "    cur = conn.cursor()\n",
    "    df.to_sql(name=\"reviews\", con=conn, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(sql_query):\n",
    "    conn = sqlite3.connect(\"exercise_database.db\")\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql_query)\n",
    "    sql_query_df = DataFrame(cur.fetchall())\n",
    "    return(sql_query_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_score_iso():\n",
    "    average_score_iso_sql = \"SELECT iso, AVG(score) AS AvgIsoScore FROM reviews GROUP BY iso;\"\n",
    "    average_score_iso_df = query_db(average_score_iso_sql)\n",
    "\n",
    "    average_score_iso_df.to_csv(\"./metrics/Average score by `iso`\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_score_by_apps_bought():\n",
    "    max_score_sql = \"SELECT apps_bought_bucket, MAX(score) AS MaxScore FROM reviews GROUP BY apps_bought_bucket;\"\n",
    "    max_score_df = query_db(max_score_sql)\n",
    "\n",
    "    max_score_df.to_csv(\"./metrics/Maximum score by `app_bought_bucket`\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_score_over_day():\n",
    "    average_score_over_day_sql = \"SELECT date, AVG(score) AS AvgDateScore FROM reviews GROUP BY date;\"\n",
    "    average_score_over_day_df = query_db(average_score_over_day_sql)\n",
    "\n",
    "    average_score_over_day_df.to_csv(\"./metrics/Average score over time (day)\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = pd.read_csv(\"./reddit_exercise_data.csv\")\n",
    "    df = df.loc[:, (df != 0).any(axis=0)]\n",
    "    cleaned_df = clean_up_df(df)\n",
    "    make_db(cleaned_df)\n",
    "    average_score_iso()\n",
    "    max_score_by_apps_bought()\n",
    "    average_score_over_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
